{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089dd45f-c57e-45df-89b6-a94013e422ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "# from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification\n",
    "\n",
    "# import emoji\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')      \n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9ae5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if text == '':\n",
    "        return ''\n",
    "    else:\n",
    "        text = text.lower()\n",
    "        text_cleaned = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "        text_cleaned = re.sub(r'#[A-Za-z0-9_]+', '', text_cleaned)\n",
    "        text_cleaned = re.sub(r'https?:\\/\\/\\S*', '', text_cleaned)\n",
    "        text_cleaned = text_cleaned.replace(',', '')\n",
    "        \n",
    "        tokenized = nlp(text_cleaned)\n",
    "        output_list = []\n",
    "        for token in tokenized:\n",
    "            if not token.is_stop:\n",
    "                output_list.append(token.lemma_)\n",
    "        \n",
    "        output = ' '.join([x for x in output_list if x != ''])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a22dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_tokenizer_model(num_classes):\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "    return bert_tokenizer, bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1319bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_embeddings(sentences, bert_tokenizer):\n",
    "    input_ids=[]\n",
    "    attention_masks=[]\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent, add_special_tokens=True, max_length=64, pad_to_max_length=True,\n",
    "                                            return_attention_mask = True)\n",
    "        input_ids.append(bert_inp['input_ids'])\n",
    "        attention_masks.append(bert_inp['attention_mask'])\n",
    "        \n",
    "    input_ids=np.asarray(input_ids)\n",
    "    attention_masks=np.array(attention_masks)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "020be231-0e97-4506-96f5-0976fa2fbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='../models/output',save_weights_only=True,\n",
    "                                                monitor='val_loss', mode='min',save_best_only=True),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "            ]\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-7, epsilon=5e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "984194d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit_bert_model(bert_model, input_ids, attention_masks, labels, input_ids_val, attention_masks_val, labels_val):\n",
    "    bert_model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "    # First fit for a minimum number of epochs\n",
    "    # bert_model.fit([input_ids, attention_masks], labels, batch_size=32,\n",
    "    #                    epochs=10, validation_data=([input_ids_val, attention_masks_val], labels_val))\n",
    "    # Then do early stopping\n",
    "    bert_model.fit([input_ids, attention_masks], labels, batch_size=32,\n",
    "                       epochs=100, callbacks=callbacks, validation_data=([input_ids_val, attention_masks_val], labels_val))\n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29964f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kennedy+2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da0ed9e-139b-4850-80ac-dc2dd719f30b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['kennedy2020'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['hegsplits', 'controlsplits'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "datasets = [\n",
    "    'kennedy2020'\n",
    "]\n",
    "splits = {dataset: {'hegsplits': {}, 'controlsplits': {}} for dataset in datasets} \n",
    "hate_ratio = 0.3\n",
    "\n",
    "def load_heg_control(splits):                                                                                  \n",
    "    \"\"\" Load heg and control dataset splits \"\"\"                                                                                                                                                                                                  \n",
    "    for dataset_name, s in splits.items():                                                                                                                                                                                                 \n",
    "        # Load csv                                                                                                                                                                                                                                   \n",
    "        dataset_path = f'../data/{dataset_name}/processed'                                                                                                                                                               \n",
    "        for splits_name in s:                                                                                                                                                                                                                       \n",
    "            for split_name in ['with_special', 'no_special']:                                                                                                                                                                                                \n",
    "                csvpath = os.path.join(dataset_path, f'{dataset_name}_{hate_ratio}hate_{splits_name}_{split_name}.csv')                                                                                                                                 \n",
    "                splits[dataset_name][splits_name][split_name] = pd.read_csv(csvpath, index_col=0) \n",
    "    return splits\n",
    "\n",
    "splits = load_heg_control(splits)\n",
    "print(splits.keys())\n",
    "splits['kennedy2020'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e4823-fa92-4db1-b456-34d40655a1af",
   "metadata": {},
   "source": [
    "## hegsplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff3c1d1-63dc-4b82-b468-7b8fde87e291",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8251\n",
      "1650\n",
      "6602\n"
     ]
    }
   ],
   "source": [
    "# Split into train, dev, test (50/10/40)\n",
    "# May have duplicates, so should split on indices\n",
    "import numpy as np\n",
    "\n",
    "df = splits[datasets[0]]['hegsplits']['with_special'].sample(frac=1, random_state=9)\n",
    "inds = {}\n",
    "inds['train'], inds['dev'], inds['test'] = np.split(list(df.index.unique()), [int(0.5*len(df)), int(0.6*len(df))])\n",
    "\n",
    "folds = {}\n",
    "for fold in inds:\n",
    "    folds[fold] = df[df.index.isin(inds[fold])]\n",
    "train, dev, test = folds['train'], folds['dev'], folds['test']\n",
    "print(len(train))\n",
    "print(len(dev))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f43fc7e-6e2a-4959-97cd-c496e85a65bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3884af6b57584a2298732f8dad821371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301701/2262418737.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['preprocess_text'] = train['text'].progress_apply(preprocess_text) # takes a long time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7fe233a0a04460bbcb25a174f01985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301701/2262418737.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dev['preprocess_text'] = dev['text'].progress_apply(preprocess_text) # takes a long time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4795397fe3a249d785883b5d4376df6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6602 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301701/2262418737.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['preprocess_text'] = test['text'].progress_apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "# Process data\n",
    "# df_contextual_train = pd.read_csv('contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "# df_contextual_train = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "\n",
    "# df_contextual_train = df_contextual_train.dropna(subset=['text'])\n",
    "# df_contextual_train['label_bin'] = df_contextual_train['labels'].apply(cad_off_or_not) # did assign it to df_contextual_test (bug?)\n",
    "# train = kennedy_data['no_heg']['train']\n",
    "# train['preprocess_text'] = train['text'].apply(preprocess_text) # takes a long time\n",
    "train['preprocess_text'] = train['text'].progress_apply(preprocess_text) # takes a long time\n",
    "\n",
    "# df_contextual_test = pd.read_csv('contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "# df_contextual_test = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "# def cad_off_or_not(label):\n",
    "#     if label == 'Neutral':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "dev['preprocess_text'] = dev['text'].progress_apply(preprocess_text) # takes a long time\n",
    "\n",
    "# df_contextual_test = df_contextual_test.dropna(subset=['text'])\n",
    "# df_contextual_test['label_bin'] = df_contextual_test['labels'].apply(cad_off_or_not)\n",
    "# test = kennedy_data['with_heg']['test']\n",
    "# test = kennedy_data['no_heg']['test']\n",
    "test['preprocess_text'] = test['text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ea79c3-5967-4f96-a19e-f652d2f6ebfd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(train['hate'].unique())\n",
    "kennedy_bert_tokenizer, kennedy_bert_model = create_bert_tokenizer_model(num_classes)\n",
    "\n",
    "# sentences_cad_train = df_contextual_train['preprocess_text']\n",
    "# labels_cad_train = df_contextual_train['label_bin']\n",
    "\n",
    "input_ids_train, attention_masks_train = create_sentence_embeddings(train['preprocess_text'], kennedy_bert_tokenizer)\n",
    "input_ids_dev, attention_masks_dev = create_sentence_embeddings(dev['preprocess_text'], kennedy_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0824c33c-72ce-45c9-b24a-6b6252dc08bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "258/258 [==============================] - 41s 129ms/step - loss: 0.6303 - accuracy: 0.6421 - val_loss: 0.5880 - val_accuracy: 0.6909\n",
      "Epoch 2/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.5687 - accuracy: 0.7006 - val_loss: 0.5607 - val_accuracy: 0.6915\n",
      "Epoch 3/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.5377 - accuracy: 0.7177 - val_loss: 0.5357 - val_accuracy: 0.7133\n",
      "Epoch 4/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.5176 - accuracy: 0.7357 - val_loss: 0.5256 - val_accuracy: 0.7303\n",
      "Epoch 5/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4984 - accuracy: 0.7528 - val_loss: 0.5111 - val_accuracy: 0.7455\n",
      "Epoch 6/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4853 - accuracy: 0.7643 - val_loss: 0.4984 - val_accuracy: 0.7600\n",
      "Epoch 7/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4731 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7612\n",
      "Epoch 8/100\n",
      "258/258 [==============================] - 32s 125ms/step - loss: 0.4644 - accuracy: 0.7777 - val_loss: 0.4945 - val_accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4551 - accuracy: 0.7849 - val_loss: 0.4906 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4465 - accuracy: 0.7837 - val_loss: 0.4796 - val_accuracy: 0.7667\n",
      "Epoch 11/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4413 - accuracy: 0.7889 - val_loss: 0.4794 - val_accuracy: 0.7679\n",
      "Epoch 12/100\n",
      "258/258 [==============================] - 32s 124ms/step - loss: 0.4331 - accuracy: 0.7968 - val_loss: 0.4765 - val_accuracy: 0.7697\n",
      "Epoch 13/100\n",
      "258/258 [==============================] - 30s 115ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.4819 - val_accuracy: 0.7661\n",
      "Epoch 14/100\n",
      "258/258 [==============================] - 30s 116ms/step - loss: 0.4264 - accuracy: 0.8022 - val_loss: 0.4796 - val_accuracy: 0.7661\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "# kennedy_model_with_heg = compile_fit_bert_model(kennedy_bert_model, input_ids_train, attention_masks_train, train['hate'], epochs=5)\n",
    "kennedy_model_with_heg = compile_fit_bert_model(kennedy_bert_model, input_ids_train, attention_masks_train, train['hate'], input_ids_dev, attention_masks_dev, dev['hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d07328aa-ec41-4d0c-a305-e7493b79a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301701/1793005534.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['label_pred'] = new_pred_labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.815278</td>\n",
       "      <td>0.677337</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>0.746307</td>\n",
       "      <td>0.773720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.531926</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>0.711335</td>\n",
       "      <td>0.782642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.851342</td>\n",
       "      <td>0.595888</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>0.723615</td>\n",
       "      <td>0.774381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4613.000000</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>6602.000000</td>\n",
       "      <td>6602.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 False         True  accuracy    macro avg  weighted avg\n",
       "precision     0.815278     0.677337  0.782642     0.746307      0.773720\n",
       "recall        0.890744     0.531926  0.782642     0.711335      0.782642\n",
       "f1-score      0.851342     0.595888  0.782642     0.723615      0.774381\n",
       "support    4613.000000  1989.000000  0.782642  6602.000000   6602.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_test, attention_masks_test = create_sentence_embeddings(test['preprocess_text'], kennedy_bert_tokenizer)\n",
    "new_preds = kennedy_model_with_heg.predict([input_ids_test, attention_masks_test],batch_size=32)\n",
    "new_pred_labels = new_preds['logits'].argmax(axis=1)\n",
    "test['label_pred'] = new_pred_labels\n",
    "test_classification = classification_report(test['hate'].tolist(), test['label_pred'].tolist(), output_dict=True)\n",
    "\n",
    "scores = pd.DataFrame(test_classification)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00ed9884-5421-4e2b-925d-07af8760bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out classification report\n",
    "model_settings = 'bert_5epochs_no_heg'\n",
    "outpath = f'{model_settings}_scores.csv'\n",
    "scores.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e88ba-aa79-48e8-8cc4-76b37a54cd8d",
   "metadata": {},
   "source": [
    "# Contextual Abuse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c30f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contextual_test = pd.read_csv('contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "# df_contextual_test = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "def cad_off_or_not(label):\n",
    "    if label == 'Neutral':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_contextual_test = df_contextual_test.dropna(subset=['text'])\n",
    "df_contextual_test['label_bin'] = df_contextual_test['labels'].apply(cad_off_or_not)\n",
    "df_contextual_test['preprocess_text'] = df_contextual_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53fbf9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'civ_bert_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41960/126541623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prediction using SemEval model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msentences_cad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_contextual_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocess_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minput_ids_cad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_masks_cad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_sentence_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences_cad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mciv_bert_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'civ_bert_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction using SemEval model\n",
    "sentences_cad = df_contextual_test['preprocess_text']\n",
    "input_ids_cad, attention_masks_cad = create_sentence_embeddings(sentences_cad, civ_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c20661",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_preds = civ_bert_model.predict([input_ids_cad, attention_masks_cad],batch_size=32)\n",
    "cad_pred_labels = cad_preds['logits'].argmax(axis=1)\n",
    "df_contextual_test['label_pred'] = cad_pred_labels\n",
    "df_dev_classification = classification_report(df_contextual_test['label_bin'].tolist(), df_contextual_test['label_pred'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf039c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAD own model\n",
    "df_contextual_train = pd.read_csv('contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "# df_contextual_train = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "\n",
    "df_contextual_train = df_contextual_train.dropna(subset=['text'])\n",
    "df_contextual_train['label_bin'] = df_contextual_train['labels'].apply(cad_off_or_not) # did assign it to df_contextual_test (bug?)\n",
    "df_contextual_train['preprocess_text'] = df_contextual_train['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e68673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\lynne\\.conda\\envs\\michael3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(df_contextual_train['label_bin'].unique()) # originally df_cad_train\n",
    "cad_bert_tokenizer, cad_bert_model = create_bert_tokenizer_model(num_classes)\n",
    "\n",
    "sentences_cad_train = df_contextual_train['preprocess_text']\n",
    "labels_cad_train = df_contextual_train['label_bin']\n",
    "\n",
    "input_ids_train_cad, attention_masks_train_cad = create_sentence_embeddings(sentences_cad_train, cad_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06272bd6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "425/425 [==============================] - 82s 157ms/step - loss: 0.4154 - accuracy: 0.8285\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 2/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.3082 - accuracy: 0.8791\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 3/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.2105 - accuracy: 0.9215\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 4/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.1208 - accuracy: 0.9582\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 5/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.0734 - accuracy: 0.9751\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    }
   ],
   "source": [
    "cad_model = compile_fit_bert_model(cad_bert_model, input_ids_train_cad, attention_masks_train_cad, labels_cad_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b72d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.864842</td>\n",
       "      <td>0.505988</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.685415</td>\n",
       "      <td>0.799589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923998</td>\n",
       "      <td>0.350259</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.637129</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.893442</td>\n",
       "      <td>0.413962</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.653702</td>\n",
       "      <td>0.806255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4342.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>5307.000000</td>\n",
       "      <td>5307.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.864842    0.505988  0.819672     0.685415      0.799589\n",
       "recall        0.923998    0.350259  0.819672     0.637129      0.819672\n",
       "f1-score      0.893442    0.413962  0.819672     0.653702      0.806255\n",
       "support    4342.000000  965.000000  0.819672  5307.000000   5307.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_cad, attention_masks_cad = create_sentence_embeddings(sentences_cad, cad_bert_tokenizer)\n",
    "cad_new_preds = cad_model.predict([input_ids_cad, attention_masks_cad],batch_size=32)\n",
    "cad_new_pred_labels = cad_new_preds['logits'].argmax(axis=1)\n",
    "df_contextual_test['label_pred_new'] = cad_new_pred_labels\n",
    "df_dev_classification = classification_report(df_contextual_test['label_bin'].tolist(), df_contextual_test['label_pred_new'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2954cf-bd8b-4b54-99b7-59106e78b6d0",
   "metadata": {},
   "source": [
    "# Lynnette's data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdd6e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Civility Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5818f8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>label_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER You are an embarrassing citizen!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>embarrassing citizen ! !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Seems hard to believe that you stood nex...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>hard believe stand guy wear short masturbate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER @USER @USER Wow !!! no wonder the Libera...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>wow ! ! ! wonder liberal get bad party bul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER And not all idiots grandstands lik...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>idiot grandstand like</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Bring on the hypocrite gungrabber. MAGA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>bring hypocrite gungrabber . maga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category  \\\n",
       "0      @USER @USER You are an embarrassing citizen!!   OFF      TIN   \n",
       "1  @USER Seems hard to believe that you stood nex...   OFF      TIN   \n",
       "2  @USER @USER @USER Wow !!! no wonder the Libera...   OFF      TIN   \n",
       "3  @USER @USER And not all idiots grandstands lik...   OFF      TIN   \n",
       "4      @USER Bring on the hypocrite gungrabber. MAGA   OFF      TIN   \n",
       "\n",
       "                                     preprocess_text  label_bin  \n",
       "0                           embarrassing citizen ! !          0  \n",
       "1    hard believe stand guy wear short masturbate...          0  \n",
       "2      wow ! ! ! wonder liberal get bad party bul...          0  \n",
       "3                              idiot grandstand like          0  \n",
       "4                  bring hypocrite gungrabber . maga          0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./civility_data/civility_data/train.tsv', sep='\\t', encoding='utf-8')\n",
    "df_train['preprocess_text'] = df_train['text'].apply(preprocess_text)\n",
    "df_train['label_bin'] = df_train['label'].apply(lambda x: 0 if x=='OFF' else 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9afa456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(df_train['label_bin'].unique())\n",
    "civ_bert_tokenizer, civ_bert_model = create_bert_tokenizer_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58f73b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10592, 10592)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df_train['preprocess_text']\n",
    "civ_labels = df_train['label_bin']\n",
    "civ_labels = np.array(civ_labels)\n",
    "len(sentences), len(civ_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52aa2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "civ_input_ids, civ_attention_masks = create_sentence_embeddings(sentences, civ_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83400611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9756WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 46s 131ms/step - loss: 0.0647 - accuracy: 0.9756\n",
      "Epoch 2/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 43s 131ms/step - loss: 0.0438 - accuracy: 0.9873\n",
      "Epoch 3/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 44s 131ms/step - loss: 0.0377 - accuracy: 0.9873\n",
      "Epoch 4/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9895WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 44s 133ms/step - loss: 0.0289 - accuracy: 0.9895\n",
      "Epoch 5/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9921WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 44s 132ms/step - loss: 0.0241 - accuracy: 0.9921\n"
     ]
    }
   ],
   "source": [
    "civ_bert_model = compile_fit_bert_model(civ_bert_model, civ_input_ids, civ_attention_masks, civ_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15cb0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>perspective_score</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>label_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>0.311852</td>\n",
       "      <td>ask native americans .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>0.566334</td>\n",
       "      <td>home drunk ! ! !     ðŸ‘Š ðŸ‡º ðŸ‡¸ ðŸ‘Š url</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110361</td>\n",
       "      <td>amazon investigate chinese employee sell inter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>0.927032</td>\n",
       "      <td>should'vetaken \" piece shit volcano . ðŸ˜‚ \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319764</td>\n",
       "      <td>obama want liberal &amp; amp ; illegal red state</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category  \\\n",
       "0  @USER She should ask a few native Americans wh...   OFF      UNT   \n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF      TIN   \n",
       "2  Amazon is investigating Chinese employees who ...   NOT      NaN   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF      UNT   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT      NaN   \n",
       "\n",
       "   perspective_score                                    preprocess_text  \\\n",
       "0           0.311852                             ask native americans .   \n",
       "1           0.566334                   home drunk ! ! !     ðŸ‘Š ðŸ‡º ðŸ‡¸ ðŸ‘Š url   \n",
       "2           0.110361  amazon investigate chinese employee sell inter...   \n",
       "3           0.927032          should'vetaken \" piece shit volcano . ðŸ˜‚ \"   \n",
       "4           0.319764       obama want liberal & amp ; illegal red state   \n",
       "\n",
       "   label_bin  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get civ dev data\n",
    "df_dev = pd.read_csv('./civility_data/civility_data/dev.tsv', sep='\\t', encoding='utf-8')\n",
    "df_dev['preprocess_text'] = df_dev['text'].apply(preprocess_text)\n",
    "df_dev['label_bin'] = df_dev['label'].apply(lambda x: 0 if x=='OFF' else 1)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "380e6935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.743630</td>\n",
       "      <td>0.767771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.732158</td>\n",
       "      <td>0.771903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.641330</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.737055</td>\n",
       "      <td>0.769156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>440.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.671642    0.815618  0.771903     0.743630      0.767771\n",
       "recall       0.613636    0.850679  0.771903     0.732158      0.771903\n",
       "f1-score     0.641330    0.832780  0.771903     0.737055      0.769156\n",
       "support    440.000000  884.000000  0.771903  1324.000000   1324.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dev = df_dev['preprocess_text']\n",
    "labels_dev = np.array(df_dev['label_bin'])\n",
    "\n",
    "dev_input_ids, dev_attention_masks = create_sentence_embeddings(sentences_dev, civ_bert_tokenizer)\n",
    "preds = civ_bert_model.predict([dev_input_ids, dev_attention_masks], batch_size=32)\n",
    "pred_labels = preds['logits'].argmax(axis=1)\n",
    "df_dev['pred'] = pred_labels\n",
    "df_dev_classification = classification_report(df_dev['label_bin'].tolist(), df_dev['pred'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e53829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# civ test data\n",
    "df_test = pd.read_csv('./civility_data/civility_data/test.tsv', sep='\\t', encoding='utf-8')\n",
    "df_test['preprocess_text'] = df_test['text'].apply(preprocess_text)\n",
    "sentences_test = df_test['preprocess_text']\n",
    "\n",
    "test_input_ids, test_attention_masks = create_sentence_embeddings(sentences_test, civ_bert_tokenizer)\n",
    "\n",
    "test_preds = bert_model.predict([input_ids_test, attention_masks_test],batch_size=32)\n",
    "test_pred_labels = test_preds['logits'].argmax(axis=1)\n",
    "df_test['label'] = test_pred_labels\n",
    "df_test.to_csv('./civility_data/civility_data/lynnette_ng_test_final.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0b2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d4abc89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gab data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7e1cf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>purity</th>\n",
       "      <th>harm</th>\n",
       "      <th>im</th>\n",
       "      <th>cv</th>\n",
       "      <th>ex</th>\n",
       "      <th>degradation</th>\n",
       "      <th>fairness</th>\n",
       "      <th>hd</th>\n",
       "      <th>...</th>\n",
       "      <th>rel</th>\n",
       "      <th>sxo</th>\n",
       "      <th>rae</th>\n",
       "      <th>nat</th>\n",
       "      <th>pol</th>\n",
       "      <th>authority</th>\n",
       "      <th>vo</th>\n",
       "      <th>idl</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29574085</td>\n",
       "      <td>People think bones are made of calcium  They a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people think bone calcium     bone high calciu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37547580</td>\n",
       "      <td>Why hasn't this disgusting illegal Obama polic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disgusting illegal obama policy completely rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21542473</td>\n",
       "      <td>Persecution for righteousness' sake, part 2:  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>persecution righteousness ' sake 2 :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26888094</td>\n",
       "      <td>Blasphemy will get you Everywhere.......</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>blasphemy .......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23041627</td>\n",
       "      <td>I don't see protecting our borders, as ALL oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>protect border nation ! have resemble martial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_id                                               text  purity  harm  \\\n",
       "0  29574085  People think bones are made of calcium  They a...       0     0   \n",
       "1  37547580  Why hasn't this disgusting illegal Obama polic...       0     0   \n",
       "2  21542473  Persecution for righteousness' sake, part 2:  ...       0     0   \n",
       "3  26888094           Blasphemy will get you Everywhere.......       0     0   \n",
       "4  23041627  I don't see protecting our borders, as ALL oth...       0     0   \n",
       "\n",
       "   im  cv  ex  degradation  fairness  hd  ...  rel  sxo  rae  nat  pol  \\\n",
       "0   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "1   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "2   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "3   0   0   0            1         0   0  ...    0    0    0    0    0   \n",
       "4   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "\n",
       "   authority  vo  idl  label_bin  \\\n",
       "0          0   0    0          0   \n",
       "1          0   0    0          0   \n",
       "2          0   0    0          0   \n",
       "3          0   0    0          0   \n",
       "4          0   0    0          0   \n",
       "\n",
       "                                     preprocess_text  \n",
       "0  people think bone calcium     bone high calciu...  \n",
       "1  disgusting illegal obama policy completely rem...  \n",
       "2             persecution righteousness ' sake 2 :    \n",
       "3                                  blasphemy .......  \n",
       "4  protect border nation ! have resemble martial ...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gab_test = pd.read_csv('/storage2/mamille3/data/hate_speech/gab_hate_corpus//gab_test.tsv', sep='\\t')\n",
    "df_gab_test['label_bin'] = df_gab_test['vo'].apply(lambda x: 1 if x==1 else 0)\n",
    "df_gab_test['preprocess_text'] = df_gab_test['text'].apply(preprocess_text)\n",
    "df_gab_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "452823ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences_gab = df_gab_test['preprocess_text']\n",
    "input_ids_gab, attention_masks_gab = create_sentence_embeddings(sentences_gab, civ_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d448a620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.794562</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>0.404833</td>\n",
       "      <td>0.744752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.217625</td>\n",
       "      <td>0.175758</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>0.196691</td>\n",
       "      <td>0.214950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.341669</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>0.184744</td>\n",
       "      <td>0.321613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2417.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.794562    0.015104   0.21495     0.404833      0.744752\n",
       "recall        0.217625    0.175758   0.21495     0.196691      0.214950\n",
       "f1-score      0.341669    0.027818   0.21495     0.184744      0.321613\n",
       "support    2417.000000  165.000000   0.21495  2582.000000   2582.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict with SemEval classifier \n",
    "gab_preds = civ_bert_model.predict([input_ids_gab, attention_masks_gab],batch_size=32)\n",
    "gab_pred_labels = gab_preds['logits'].argmax(axis=1)\n",
    "df_gab_test['label_pred'] = gab_pred_labels\n",
    "df_dev_classification = classification_report(df_gab_test['label_bin'].tolist(), df_gab_test['label_pred'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b756197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Gab's own classifier\n",
    "df_gab_train = pd.read_csv('./gab_data/gab_data/gab_train.tsv', sep='\\t')\n",
    "df_gab_train['label_bin'] = df_gab_train['vo'].apply(lambda x: 1 if x==1 else 0)\n",
    "df_gab_train['preprocess_text'] = df_gab_train['text'].apply(preprocess_text)\n",
    "\n",
    "num_gab_classes=len(df_gab_train['label_bin'].unique())\n",
    "gab_bert_tokenizer, gab_bert_model = create_bert_tokenizer_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87b948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences_gab_train = df_gab_train['preprocess_text']\n",
    "labels_gab_train = np.array(df_gab_train['label_bin'])\n",
    "\n",
    "input_ids_train_gab, attention_masks_train_gab = create_sentence_embeddings(sentences_gab_train, gab_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "646/646 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9553WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "646/646 [==============================] - 101s 145ms/step - loss: 0.2185 - accuracy: 0.9553\n",
      "Epoch 2/5\n",
      "646/646 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9349WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "646/646 [==============================] - 94s 145ms/step - loss: 0.1779 - accuracy: 0.9349\n",
      "Epoch 3/5\n",
      "454/646 [====================>.........] - ETA: 27s - loss: 0.1914 - accuracy: 0.9341"
     ]
    }
   ],
   "source": [
    "gab_model = compile_fit_bert_model(gab_bert_model, input_ids_train_gab, attention_masks_train_gab, labels_gab_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gab_new_preds = gab_model.predict([input_ids_gab, attention_masks_gab],batch_size=32)\n",
    "gab_new_pred_labels = gab_new_preds['logits'].argmax(axis=1)\n",
    "df_gab_test['label_pred_new'] = gab_new_pred_labels\n",
    "df_dev_classification = classification_report(df_gab_test['label_bin'].tolist(), df_gab_test['label_pred_new'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab39192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
