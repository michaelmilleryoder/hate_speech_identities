{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744d8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import keras\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "# import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "# from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification\n",
    "# import emoji\n",
    "# import torch\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')      \n",
    "\n",
    "# Set CPU usage\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9ae5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if text == '':\n",
    "        return ''\n",
    "    else:\n",
    "        text = text.lower()\n",
    "        text_cleaned = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "        text_cleaned = re.sub(r'#[A-Za-z0-9_]+', '', text_cleaned)\n",
    "        text_cleaned = re.sub(r'https?:\\/\\/\\S*', '', text_cleaned)\n",
    "        text_cleaned = text_cleaned.replace(',', '')\n",
    "        \n",
    "        tokenized = nlp(text_cleaned)\n",
    "        output_list = []\n",
    "        for token in tokenized:\n",
    "            if not token.is_stop:\n",
    "                output_list.append(token.lemma_)\n",
    "        \n",
    "        output = ' '.join([x for x in output_list if x != ''])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a22dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_tokenizer_model(num_classes):\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "    return bert_tokenizer, bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1319bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_embeddings(sentences, bert_tokenizer):\n",
    "    input_ids=[]\n",
    "    attention_masks=[]\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent, add_special_tokens=True, max_length=64, pad_to_max_length=True,\n",
    "                                            return_attention_mask = True)\n",
    "        input_ids.append(bert_inp['input_ids'])\n",
    "        attention_masks.append(bert_inp['attention_mask'])\n",
    "        \n",
    "    input_ids=np.asarray(input_ids)\n",
    "    attention_masks=np.array(attention_masks)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93695815",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./output',save_weights_only=True,\n",
    "                                                monitor='val_loss',mode='min',save_best_only=True)]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "984194d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit_bert_model(bert_model, input_ids, attention_masks, labels, epochs):\n",
    "    bert_model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n",
    "    bert_model.fit([input_ids, attention_masks], labels, batch_size=32,\n",
    "                       epochs=epochs, callbacks=callbacks)\n",
    "    return bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdd6e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Civility Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5818f8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>label_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER You are an embarrassing citizen!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>embarrassing citizen ! !</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER Seems hard to believe that you stood nex...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>hard believe stand guy wear short masturbate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER @USER @USER Wow !!! no wonder the Libera...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>wow ! ! ! wonder liberal get bad party bul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER And not all idiots grandstands lik...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>idiot grandstand like</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Bring on the hypocrite gungrabber. MAGA</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>bring hypocrite gungrabber . maga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category  \\\n",
       "0      @USER @USER You are an embarrassing citizen!!   OFF      TIN   \n",
       "1  @USER Seems hard to believe that you stood nex...   OFF      TIN   \n",
       "2  @USER @USER @USER Wow !!! no wonder the Libera...   OFF      TIN   \n",
       "3  @USER @USER And not all idiots grandstands lik...   OFF      TIN   \n",
       "4      @USER Bring on the hypocrite gungrabber. MAGA   OFF      TIN   \n",
       "\n",
       "                                     preprocess_text  label_bin  \n",
       "0                           embarrassing citizen ! !          0  \n",
       "1    hard believe stand guy wear short masturbate...          0  \n",
       "2      wow ! ! ! wonder liberal get bad party bul...          0  \n",
       "3                              idiot grandstand like          0  \n",
       "4                  bring hypocrite gungrabber . maga          0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./civility_data/civility_data/train.tsv', sep='\\t', encoding='utf-8')\n",
    "df_train['preprocess_text'] = df_train['text'].apply(preprocess_text)\n",
    "df_train['label_bin'] = df_train['label'].apply(lambda x: 0 if x=='OFF' else 1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9afa456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(df_train['label_bin'].unique())\n",
    "civ_bert_tokenizer, civ_bert_model = create_bert_tokenizer_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58f73b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10592, 10592)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df_train['preprocess_text']\n",
    "civ_labels = df_train['label_bin']\n",
    "civ_labels = np.array(civ_labels)\n",
    "len(sentences), len(civ_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52aa2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "civ_input_ids, civ_attention_masks = create_sentence_embeddings(sentences, civ_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83400611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9756WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 46s 131ms/step - loss: 0.0647 - accuracy: 0.9756\n",
      "Epoch 2/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 43s 131ms/step - loss: 0.0438 - accuracy: 0.9873\n",
      "Epoch 3/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 44s 131ms/step - loss: 0.0377 - accuracy: 0.9873\n",
      "Epoch 4/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9895WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 44s 133ms/step - loss: 0.0289 - accuracy: 0.9895\n",
      "Epoch 5/5\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9921WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "331/331 [==============================] - 44s 132ms/step - loss: 0.0241 - accuracy: 0.9921\n"
     ]
    }
   ],
   "source": [
    "civ_bert_model = compile_fit_bert_model(civ_bert_model, civ_input_ids, civ_attention_masks, civ_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15cb0770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>perspective_score</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>label_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>0.311852</td>\n",
       "      <td>ask native americans .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>0.566334</td>\n",
       "      <td>home drunk ! ! !     ðŸ‘Š ðŸ‡º ðŸ‡¸ ðŸ‘Š url</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110361</td>\n",
       "      <td>amazon investigate chinese employee sell inter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>0.927032</td>\n",
       "      <td>should'vetaken \" piece shit volcano . ðŸ˜‚ \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319764</td>\n",
       "      <td>obama want liberal &amp; amp ; illegal red state</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label category  \\\n",
       "0  @USER She should ask a few native Americans wh...   OFF      UNT   \n",
       "1  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...   OFF      TIN   \n",
       "2  Amazon is investigating Chinese employees who ...   NOT      NaN   \n",
       "3  @USER Someone should'veTaken\" this piece of sh...   OFF      UNT   \n",
       "4  @USER @USER Obama wanted liberals &amp; illega...   NOT      NaN   \n",
       "\n",
       "   perspective_score                                    preprocess_text  \\\n",
       "0           0.311852                             ask native americans .   \n",
       "1           0.566334                   home drunk ! ! !     ðŸ‘Š ðŸ‡º ðŸ‡¸ ðŸ‘Š url   \n",
       "2           0.110361  amazon investigate chinese employee sell inter...   \n",
       "3           0.927032          should'vetaken \" piece shit volcano . ðŸ˜‚ \"   \n",
       "4           0.319764       obama want liberal & amp ; illegal red state   \n",
       "\n",
       "   label_bin  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get civ dev data\n",
    "df_dev = pd.read_csv('./civility_data/civility_data/dev.tsv', sep='\\t', encoding='utf-8')\n",
    "df_dev['preprocess_text'] = df_dev['text'].apply(preprocess_text)\n",
    "df_dev['label_bin'] = df_dev['label'].apply(lambda x: 0 if x=='OFF' else 1)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "380e6935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.743630</td>\n",
       "      <td>0.767771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.732158</td>\n",
       "      <td>0.771903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.641330</td>\n",
       "      <td>0.832780</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>0.737055</td>\n",
       "      <td>0.769156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>440.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>0.771903</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy    macro avg  weighted avg\n",
       "precision    0.671642    0.815618  0.771903     0.743630      0.767771\n",
       "recall       0.613636    0.850679  0.771903     0.732158      0.771903\n",
       "f1-score     0.641330    0.832780  0.771903     0.737055      0.769156\n",
       "support    440.000000  884.000000  0.771903  1324.000000   1324.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dev = df_dev['preprocess_text']\n",
    "labels_dev = np.array(df_dev['label_bin'])\n",
    "\n",
    "dev_input_ids, dev_attention_masks = create_sentence_embeddings(sentences_dev, civ_bert_tokenizer)\n",
    "preds = civ_bert_model.predict([dev_input_ids, dev_attention_masks], batch_size=32)\n",
    "pred_labels = preds['logits'].argmax(axis=1)\n",
    "df_dev['pred'] = pred_labels\n",
    "df_dev_classification = classification_report(df_dev['label_bin'].tolist(), df_dev['pred'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e53829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# civ test data\n",
    "df_test = pd.read_csv('./civility_data/civility_data/test.tsv', sep='\\t', encoding='utf-8')\n",
    "df_test['preprocess_text'] = df_test['text'].apply(preprocess_text)\n",
    "sentences_test = df_test['preprocess_text']\n",
    "\n",
    "test_input_ids, test_attention_masks = create_sentence_embeddings(sentences_test, civ_bert_tokenizer)\n",
    "\n",
    "test_preds = bert_model.predict([input_ids_test, attention_masks_test],batch_size=32)\n",
    "test_pred_labels = test_preds['logits'].argmax(axis=1)\n",
    "df_test['label'] = test_pred_labels\n",
    "df_test.to_csv('./civility_data/civility_data/lynnette_ng_test_final.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0b2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d4abc89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Gab data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7e1cf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>purity</th>\n",
       "      <th>harm</th>\n",
       "      <th>im</th>\n",
       "      <th>cv</th>\n",
       "      <th>ex</th>\n",
       "      <th>degradation</th>\n",
       "      <th>fairness</th>\n",
       "      <th>hd</th>\n",
       "      <th>...</th>\n",
       "      <th>rel</th>\n",
       "      <th>sxo</th>\n",
       "      <th>rae</th>\n",
       "      <th>nat</th>\n",
       "      <th>pol</th>\n",
       "      <th>authority</th>\n",
       "      <th>vo</th>\n",
       "      <th>idl</th>\n",
       "      <th>label_bin</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29574085</td>\n",
       "      <td>People think bones are made of calcium  They a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people think bone calcium     bone high calciu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37547580</td>\n",
       "      <td>Why hasn't this disgusting illegal Obama polic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>disgusting illegal obama policy completely rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21542473</td>\n",
       "      <td>Persecution for righteousness' sake, part 2:  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>persecution righteousness ' sake 2 :</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26888094</td>\n",
       "      <td>Blasphemy will get you Everywhere.......</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>blasphemy .......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23041627</td>\n",
       "      <td>I don't see protecting our borders, as ALL oth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>protect border nation ! have resemble martial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_id                                               text  purity  harm  \\\n",
       "0  29574085  People think bones are made of calcium  They a...       0     0   \n",
       "1  37547580  Why hasn't this disgusting illegal Obama polic...       0     0   \n",
       "2  21542473  Persecution for righteousness' sake, part 2:  ...       0     0   \n",
       "3  26888094           Blasphemy will get you Everywhere.......       0     0   \n",
       "4  23041627  I don't see protecting our borders, as ALL oth...       0     0   \n",
       "\n",
       "   im  cv  ex  degradation  fairness  hd  ...  rel  sxo  rae  nat  pol  \\\n",
       "0   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "1   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "2   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "3   0   0   0            1         0   0  ...    0    0    0    0    0   \n",
       "4   0   0   0            0         0   0  ...    0    0    0    0    0   \n",
       "\n",
       "   authority  vo  idl  label_bin  \\\n",
       "0          0   0    0          0   \n",
       "1          0   0    0          0   \n",
       "2          0   0    0          0   \n",
       "3          0   0    0          0   \n",
       "4          0   0    0          0   \n",
       "\n",
       "                                     preprocess_text  \n",
       "0  people think bone calcium     bone high calciu...  \n",
       "1  disgusting illegal obama policy completely rem...  \n",
       "2             persecution righteousness ' sake 2 :    \n",
       "3                                  blasphemy .......  \n",
       "4  protect border nation ! have resemble martial ...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gab_test = pd.read_csv('/storage2/mamille3/data/hate_speech/gab_hate_corpus//gab_test.tsv', sep='\\t')\n",
    "df_gab_test['label_bin'] = df_gab_test['vo'].apply(lambda x: 1 if x==1 else 0)\n",
    "df_gab_test['preprocess_text'] = df_gab_test['text'].apply(preprocess_text)\n",
    "df_gab_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "452823ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences_gab = df_gab_test['preprocess_text']\n",
    "input_ids_gab, attention_masks_gab = create_sentence_embeddings(sentences_gab, civ_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d448a620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.794562</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>0.404833</td>\n",
       "      <td>0.744752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.217625</td>\n",
       "      <td>0.175758</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>0.196691</td>\n",
       "      <td>0.214950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.341669</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>0.184744</td>\n",
       "      <td>0.321613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2417.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.21495</td>\n",
       "      <td>2582.000000</td>\n",
       "      <td>2582.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.794562    0.015104   0.21495     0.404833      0.744752\n",
       "recall        0.217625    0.175758   0.21495     0.196691      0.214950\n",
       "f1-score      0.341669    0.027818   0.21495     0.184744      0.321613\n",
       "support    2417.000000  165.000000   0.21495  2582.000000   2582.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict with SemEval classifier \n",
    "gab_preds = civ_bert_model.predict([input_ids_gab, attention_masks_gab],batch_size=32)\n",
    "gab_pred_labels = gab_preds['logits'].argmax(axis=1)\n",
    "df_gab_test['label_pred'] = gab_pred_labels\n",
    "df_dev_classification = classification_report(df_gab_test['label_bin'].tolist(), df_gab_test['label_pred'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b756197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Gab's own classifier\n",
    "df_gab_train = pd.read_csv('./gab_data/gab_data/gab_train.tsv', sep='\\t')\n",
    "df_gab_train['label_bin'] = df_gab_train['vo'].apply(lambda x: 1 if x==1 else 0)\n",
    "df_gab_train['preprocess_text'] = df_gab_train['text'].apply(preprocess_text)\n",
    "\n",
    "num_gab_classes=len(df_gab_train['label_bin'].unique())\n",
    "gab_bert_tokenizer, gab_bert_model = create_bert_tokenizer_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87b948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentences_gab_train = df_gab_train['preprocess_text']\n",
    "labels_gab_train = np.array(df_gab_train['label_bin'])\n",
    "\n",
    "input_ids_train_gab, attention_masks_train_gab = create_sentence_embeddings(sentences_gab_train, gab_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "646/646 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9553WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "646/646 [==============================] - 101s 145ms/step - loss: 0.2185 - accuracy: 0.9553\n",
      "Epoch 2/5\n",
      "646/646 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9349WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "646/646 [==============================] - 94s 145ms/step - loss: 0.1779 - accuracy: 0.9349\n",
      "Epoch 3/5\n",
      "454/646 [====================>.........] - ETA: 27s - loss: 0.1914 - accuracy: 0.9341"
     ]
    }
   ],
   "source": [
    "gab_model = compile_fit_bert_model(gab_bert_model, input_ids_train_gab, attention_masks_train_gab, labels_gab_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gab_new_preds = gab_model.predict([input_ids_gab, attention_masks_gab],batch_size=32)\n",
    "gab_new_pred_labels = gab_new_preds['logits'].argmax(axis=1)\n",
    "df_gab_test['label_pred_new'] = gab_new_pred_labels\n",
    "df_dev_classification = classification_report(df_gab_test['label_bin'].tolist(), df_gab_test['label_pred_new'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab39192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29964f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kennedy+2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5755021a-1512-4531-b813-cf57be984158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['with_heg', 'no_heg'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "import pickle\n",
    "path = 'kennedy2020_hegsplits_0.3hate.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    kennedy_data = pickle.load(f)\n",
    "kennedy_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e4823-fa92-4db1-b456-34d40655a1af",
   "metadata": {},
   "source": [
    "## with_heg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b9a9fa2-4904-4a6d-abf5-1c34bfe366f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'dev', 'test'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kennedy_data['with_heg'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1f7a3c-6cb3-4e4a-827d-c40176fa8a40",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment_id',\n",
       " 'annotator_id',\n",
       " 'platform',\n",
       " 'sentiment',\n",
       " 'respect',\n",
       " 'insult',\n",
       " 'humiliate',\n",
       " 'status',\n",
       " 'dehumanize',\n",
       " 'violence',\n",
       " 'genocide',\n",
       " 'attack_defend',\n",
       " 'hatespeech',\n",
       " 'hate_speech_score',\n",
       " 'text',\n",
       " 'infitms',\n",
       " 'outfitms',\n",
       " 'annotator_severity',\n",
       " 'std_err',\n",
       " 'annotator_infitms',\n",
       " 'annotator_outfitms',\n",
       " 'hypothesis',\n",
       " 'target_race_asian',\n",
       " 'target_race_black',\n",
       " 'target_race_latinx',\n",
       " 'target_race_middle_eastern',\n",
       " 'target_race_native_american',\n",
       " 'target_race_pacific_islander',\n",
       " 'target_race_white',\n",
       " 'target_race_other',\n",
       " 'target_race',\n",
       " 'target_religion_atheist',\n",
       " 'target_religion_buddhist',\n",
       " 'target_religion_christian',\n",
       " 'target_religion_hindu',\n",
       " 'target_religion_jewish',\n",
       " 'target_religion_mormon',\n",
       " 'target_religion_muslim',\n",
       " 'target_religion_other',\n",
       " 'target_religion',\n",
       " 'target_origin_immigrant',\n",
       " 'target_origin_migrant_worker',\n",
       " 'target_origin_specific_country',\n",
       " 'target_origin_undocumented',\n",
       " 'target_origin_other',\n",
       " 'target_origin',\n",
       " 'target_gender_men',\n",
       " 'target_gender_non_binary',\n",
       " 'target_gender_transgender_men',\n",
       " 'target_gender_transgender_unspecified',\n",
       " 'target_gender_transgender_women',\n",
       " 'target_gender_women',\n",
       " 'target_gender_other',\n",
       " 'target_gender',\n",
       " 'target_sexuality_bisexual',\n",
       " 'target_sexuality_gay',\n",
       " 'target_sexuality_lesbian',\n",
       " 'target_sexuality_straight',\n",
       " 'target_sexuality_other',\n",
       " 'target_sexuality',\n",
       " 'target_age_children',\n",
       " 'target_age_teenagers',\n",
       " 'target_age_young_adults',\n",
       " 'target_age_middle_aged',\n",
       " 'target_age_seniors',\n",
       " 'target_age_other',\n",
       " 'target_age',\n",
       " 'target_disability_physical',\n",
       " 'target_disability_cognitive',\n",
       " 'target_disability_neurological',\n",
       " 'target_disability_visually_impaired',\n",
       " 'target_disability_hearing_impaired',\n",
       " 'target_disability_unspecific',\n",
       " 'target_disability_other',\n",
       " 'target_disability',\n",
       " 'annotator_gender',\n",
       " 'annotator_trans',\n",
       " 'annotator_educ',\n",
       " 'annotator_income',\n",
       " 'annotator_ideology',\n",
       " 'annotator_gender_men',\n",
       " 'annotator_gender_women',\n",
       " 'annotator_gender_non_binary',\n",
       " 'annotator_gender_prefer_not_to_say',\n",
       " 'annotator_gender_self_describe',\n",
       " 'annotator_transgender',\n",
       " 'annotator_cisgender',\n",
       " 'annotator_transgender_prefer_not_to_say',\n",
       " 'annotator_education_some_high_school',\n",
       " 'annotator_education_high_school_grad',\n",
       " 'annotator_education_some_college',\n",
       " 'annotator_education_college_grad_aa',\n",
       " 'annotator_education_college_grad_ba',\n",
       " 'annotator_education_professional_degree',\n",
       " 'annotator_education_masters',\n",
       " 'annotator_education_phd',\n",
       " 'annotator_income_<10k',\n",
       " 'annotator_income_10k-50k',\n",
       " 'annotator_income_50k-100k',\n",
       " 'annotator_income_100k-200k',\n",
       " 'annotator_income_>200k',\n",
       " 'annotator_ideology_extremeley_conservative',\n",
       " 'annotator_ideology_conservative',\n",
       " 'annotator_ideology_slightly_conservative',\n",
       " 'annotator_ideology_neutral',\n",
       " 'annotator_ideology_slightly_liberal',\n",
       " 'annotator_ideology_liberal',\n",
       " 'annotator_ideology_extremeley_liberal',\n",
       " 'annotator_ideology_no_opinion',\n",
       " 'annotator_race_asian',\n",
       " 'annotator_race_black',\n",
       " 'annotator_race_latinx',\n",
       " 'annotator_race_middle_eastern',\n",
       " 'annotator_race_native_american',\n",
       " 'annotator_race_pacific_islander',\n",
       " 'annotator_race_white',\n",
       " 'annotator_race_other',\n",
       " 'annotator_age',\n",
       " 'annotator_religion_atheist',\n",
       " 'annotator_religion_buddhist',\n",
       " 'annotator_religion_christian',\n",
       " 'annotator_religion_hindu',\n",
       " 'annotator_religion_jewish',\n",
       " 'annotator_religion_mormon',\n",
       " 'annotator_religion_muslim',\n",
       " 'annotator_religion_nothing',\n",
       " 'annotator_religion_other',\n",
       " 'annotator_sexuality_bisexual',\n",
       " 'annotator_sexuality_gay',\n",
       " 'annotator_sexuality_straight',\n",
       " 'annotator_sexuality_other',\n",
       " 'group_label',\n",
       " 'hate']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kennedy_data['with_heg']['train'].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bcc2cbe-43d8-4481-a04e-5a618398c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "# df_contextual_train = pd.read_csv('contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "# df_contextual_train = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "\n",
    "# df_contextual_train = df_contextual_train.dropna(subset=['text'])\n",
    "# df_contextual_train['label_bin'] = df_contextual_train['labels'].apply(cad_off_or_not) # did assign it to df_contextual_test (bug?)\n",
    "train = kennedy_data['no_heg']['train']\n",
    "train['preprocess_text'] = train['text'].apply(preprocess_text) # takes a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "182386be-90eb-4a87-94c8-b90a03b70402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_contextual_test = pd.read_csv('contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "# df_contextual_test = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "# def cad_off_or_not(label):\n",
    "#     if label == 'Neutral':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "# df_contextual_test = df_contextual_test.dropna(subset=['text'])\n",
    "# df_contextual_test['label_bin'] = df_contextual_test['labels'].apply(cad_off_or_not)\n",
    "# test = kennedy_data['with_heg']['test']\n",
    "test = kennedy_data['no_heg']['test']\n",
    "test['preprocess_text'] = test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ea79c3-5967-4f96-a19e-f652d2f6ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\lynne\\.conda\\envs\\michael3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(train['hate'].unique())\n",
    "kennedy_bert_tokenizer, kennedy_bert_model = create_bert_tokenizer_model(num_classes)\n",
    "\n",
    "# sentences_cad_train = df_contextual_train['preprocess_text']\n",
    "# labels_cad_train = df_contextual_train['label_bin']\n",
    "\n",
    "input_ids_train, attention_masks_train = create_sentence_embeddings(train['preprocess_text'], kennedy_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0824c33c-72ce-45c9-b24a-6b6252dc08bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2293/2293 [==============================] - 374s 160ms/step - loss: 0.1914 - accuracy: 0.9522\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 2/5\n",
      "2293/2293 [==============================] - 366s 160ms/step - loss: 0.1006 - accuracy: 0.9603\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 3/5\n",
      "2293/2293 [==============================] - 367s 160ms/step - loss: 0.0493 - accuracy: 0.9818\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 4/5\n",
      "2293/2293 [==============================] - 368s 161ms/step - loss: 0.0301 - accuracy: 0.9884\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 5/5\n",
      "2293/2293 [==============================] - 368s 161ms/step - loss: 0.0228 - accuracy: 0.9915\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    }
   ],
   "source": [
    "kennedy_model_no_heg = compile_fit_bert_model(kennedy_bert_model, input_ids_train, attention_masks_train, train['hate'], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d07328aa-ec41-4d0c-a305-e7493b79a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lynne\\.conda\\envs\\michael3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.977033</td>\n",
       "      <td>0.949022</td>\n",
       "      <td>0.968674</td>\n",
       "      <td>0.963028</td>\n",
       "      <td>0.968649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.978288</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>0.968674</td>\n",
       "      <td>0.962229</td>\n",
       "      <td>0.968674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.977660</td>\n",
       "      <td>0.947594</td>\n",
       "      <td>0.968674</td>\n",
       "      <td>0.962627</td>\n",
       "      <td>0.968661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>25700.000000</td>\n",
       "      <td>10979.000000</td>\n",
       "      <td>0.968674</td>\n",
       "      <td>36679.000000</td>\n",
       "      <td>36679.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  False          True  accuracy     macro avg  weighted avg\n",
       "precision      0.977033      0.949022  0.968674      0.963028      0.968649\n",
       "recall         0.978288      0.946170  0.968674      0.962229      0.968674\n",
       "f1-score       0.977660      0.947594  0.968674      0.962627      0.968661\n",
       "support    25700.000000  10979.000000  0.968674  36679.000000  36679.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_test, attention_masks_test = create_sentence_embeddings(test['preprocess_text'], kennedy_bert_tokenizer)\n",
    "new_preds = kennedy_model_no_heg.predict([input_ids_test, attention_masks_test],batch_size=32)\n",
    "new_pred_labels = new_preds['logits'].argmax(axis=1)\n",
    "test['label_pred'] = new_pred_labels\n",
    "test_classification = classification_report(test['hate'].tolist(), test['label_pred'].tolist(), output_dict=True)\n",
    "\n",
    "scores = pd.DataFrame(test_classification)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00ed9884-5421-4e2b-925d-07af8760bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out classification report\n",
    "model_settings = 'bert_5epochs_no_heg'\n",
    "outpath = f'{model_settings}_scores.csv'\n",
    "scores.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e88ba-aa79-48e8-8cc4-76b37a54cd8d",
   "metadata": {},
   "source": [
    "## Contextual Abuse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c30f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contextual_test = pd.read_csv('contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "# df_contextual_test = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_test.tsv', sep='\\t')\n",
    "def cad_off_or_not(label):\n",
    "    if label == 'Neutral':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_contextual_test = df_contextual_test.dropna(subset=['text'])\n",
    "df_contextual_test['label_bin'] = df_contextual_test['labels'].apply(cad_off_or_not)\n",
    "df_contextual_test['preprocess_text'] = df_contextual_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53fbf9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'civ_bert_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_41960/126541623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prediction using SemEval model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msentences_cad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_contextual_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preprocess_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minput_ids_cad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_masks_cad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_sentence_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences_cad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mciv_bert_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'civ_bert_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Prediction using SemEval model\n",
    "sentences_cad = df_contextual_test['preprocess_text']\n",
    "input_ids_cad, attention_masks_cad = create_sentence_embeddings(sentences_cad, civ_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c20661",
   "metadata": {},
   "outputs": [],
   "source": [
    "cad_preds = civ_bert_model.predict([input_ids_cad, attention_masks_cad],batch_size=32)\n",
    "cad_pred_labels = cad_preds['logits'].argmax(axis=1)\n",
    "df_contextual_test['label_pred'] = cad_pred_labels\n",
    "df_dev_classification = classification_report(df_contextual_test['label_bin'].tolist(), df_contextual_test['label_pred'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf039c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAD own model\n",
    "df_contextual_train = pd.read_csv('contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "# df_contextual_train = pd.read_csv('/storage2/mamille3/data/hate_speech/contextual_abuse_dataset/cad_v1_1_train.tsv', sep='\\t')\n",
    "\n",
    "df_contextual_train = df_contextual_train.dropna(subset=['text'])\n",
    "df_contextual_train['label_bin'] = df_contextual_train['labels'].apply(cad_off_or_not) # did assign it to df_contextual_test (bug?)\n",
    "df_contextual_train['preprocess_text'] = df_contextual_train['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e68673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\lynne\\.conda\\envs\\michael3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(df_contextual_train['label_bin'].unique()) # originally df_cad_train\n",
    "cad_bert_tokenizer, cad_bert_model = create_bert_tokenizer_model(num_classes)\n",
    "\n",
    "sentences_cad_train = df_contextual_train['preprocess_text']\n",
    "labels_cad_train = df_contextual_train['label_bin']\n",
    "\n",
    "input_ids_train_cad, attention_masks_train_cad = create_sentence_embeddings(sentences_cad_train, cad_bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06272bd6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "425/425 [==============================] - 82s 157ms/step - loss: 0.4154 - accuracy: 0.8285\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 2/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.3082 - accuracy: 0.8791\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 3/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.2105 - accuracy: 0.9215\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 4/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.1208 - accuracy: 0.9582\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 5/5\n",
      "425/425 [==============================] - 67s 158ms/step - loss: 0.0734 - accuracy: 0.9751\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    }
   ],
   "source": [
    "cad_model = compile_fit_bert_model(cad_bert_model, input_ids_train_cad, attention_masks_train_cad, labels_cad_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b72d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.864842</td>\n",
       "      <td>0.505988</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.685415</td>\n",
       "      <td>0.799589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923998</td>\n",
       "      <td>0.350259</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.637129</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.893442</td>\n",
       "      <td>0.413962</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.653702</td>\n",
       "      <td>0.806255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4342.000000</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>5307.000000</td>\n",
       "      <td>5307.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.864842    0.505988  0.819672     0.685415      0.799589\n",
       "recall        0.923998    0.350259  0.819672     0.637129      0.819672\n",
       "f1-score      0.893442    0.413962  0.819672     0.653702      0.806255\n",
       "support    4342.000000  965.000000  0.819672  5307.000000   5307.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_cad, attention_masks_cad = create_sentence_embeddings(sentences_cad, cad_bert_tokenizer)\n",
    "cad_new_preds = cad_model.predict([input_ids_cad, attention_masks_cad],batch_size=32)\n",
    "cad_new_pred_labels = cad_new_preds['logits'].argmax(axis=1)\n",
    "df_contextual_test['label_pred_new'] = cad_new_pred_labels\n",
    "df_dev_classification = classification_report(df_contextual_test['label_bin'].tolist(), df_contextual_test['label_pred_new'].tolist(), output_dict=True)\n",
    "pd.DataFrame(df_dev_classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
